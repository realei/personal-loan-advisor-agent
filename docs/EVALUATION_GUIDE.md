# ğŸ¯ Agentè¯„ä¼°ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æœ¬è¯„ä¼°ç³»ç»Ÿç›´æ¥ä»MongoDBä¸­æå–Agentçš„çœŸå®è¿è¡Œæ•°æ®ï¼Œä½¿ç”¨DeepEvalæ¡†æ¶è¿›è¡Œå¤šç»´åº¦è¯„ä¼°ã€‚**æ— éœ€ä¿®æ”¹ç°æœ‰Agentä»£ç **ã€‚

## ç‰¹æ€§

âœ… **ä»MongoDBç›´æ¥è·å–æµ‹è¯•æ•°æ®** - ä½¿ç”¨çœŸå®çš„ç”Ÿäº§æ•°æ®è¿›è¡Œè¯„ä¼°
âœ… **æ”¯æŒå¤šä¸ªè¯„ä¼°æŒ‡æ ‡** - æ¯ä¸ªtestcaseå¯ä»¥åŒæ—¶è¯„ä¼°å¤šä¸ªmetrics
âœ… **Reference-basedå’ŒReferencelessæ··åˆ** - çµæ´»çš„è¯„ä¼°æ–¹å¼
âœ… **è‡ªå®šä¹‰æŒ‡æ ‡** - å·¥å…·å‡†ç¡®æ€§ã€å‚æ•°éªŒè¯ç­‰é¢†åŸŸç‰¹å®šæŒ‡æ ‡
âœ… **CI/CDé›†æˆ** - æ”¯æŒpytestå’Œè‡ªåŠ¨åŒ–æµ‹è¯•

## å¿«é€Ÿå¼€å§‹

### 1. è¿è¡Œå¿«é€Ÿè¯„ä¼°

```bash
# è¯„ä¼°æœ€è¿‘24å°æ—¶çš„5ä¸ªè¿è¡Œ
uv run python run_evaluation.py --mode recent --hours 24 --limit 5

# è¯„ä¼°åŒ…å«"è®¡ç®—æœˆä¾›"çš„è¿è¡Œ
uv run python run_evaluation.py --mode pattern --pattern "è®¡ç®—æœˆä¾›" --limit 3

# ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
uv run python run_evaluation.py --mode report --output evaluation_results.json
```

### 2. è¿è¡ŒPytestæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰è¯„ä¼°æµ‹è¯•
uv run pytest tests/test_mongodb_deepeval.py -v

# åªè¿è¡Œè´¨é‡æµ‹è¯•
uv run pytest tests/test_mongodb_deepeval.py::TestMongoDBDeepEval::test_recent_runs_quality -v

# è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
uv run pytest tests/test_mongodb_deepeval.py -m benchmark -v

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
uv run pytest tests/test_mongodb_deepeval.py --html=report.html
```

### 3. ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

```bash
# ç›´æ¥ç”ŸæˆæŠ¥å‘Šï¼ˆä¸è¿è¡Œæµ‹è¯•ï¼‰
uv run python tests/test_mongodb_deepeval.py report
```

## è¯„ä¼°æŒ‡æ ‡è¯´æ˜

### DeepEvalæ ‡å‡†æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | é˜ˆå€¼ | æ•°æ®æº |
|------|------|------|--------|
| Answer Relevancy | å›ç­”ä¸é—®é¢˜çš„ç›¸å…³æ€§ | 0.7 | input vs output |
| Faithfulness | å›ç­”åŸºäºäº‹å®çš„ç¨‹åº¦ | 0.75 | tool_responses vs output |
| Hallucination | è™šæ„ä¿¡æ¯æ£€æµ‹ | 0.3â†“ | æ£€æŸ¥outputä¸­çš„è™šæ„ |
| Bias | åè§æ£€æµ‹ | 0.3â†“ | åˆ†æoutputå†…å®¹ |
| Contextual Relevancy | ä¸Šä¸‹æ–‡ç›¸å…³æ€§ | 0.7 | context vs output |

### è‡ªå®šä¹‰AgenticæŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | é˜ˆå€¼ | è¯„ä¼°æ–¹å¼ |
|------|------|------|----------|
| Tool Accuracy | å·¥å…·é€‰æ‹©å‡†ç¡®æ€§ | 0.8 | actual vs expected tools |
| Parameter Correctness | å‚æ•°åˆç†æ€§ | 0.9 | ReferencelesséªŒè¯ |
| Tool Chain Logic | å·¥å…·è°ƒç”¨é¡ºåºé€»è¾‘ | 0.85 | é¡ºåºåˆç†æ€§æ£€æŸ¥ |
| Response Time | å“åº”æ—¶é—´ | 5.0s | ä»metricsè·å– |
| Token Efficiency | Tokenä½¿ç”¨æ•ˆç‡ | 4000 | æ€»tokenæ¶ˆè€— |

## æ–‡ä»¶ç»“æ„

```
evaluation/
â”œâ”€â”€ evaluation_framework.py    # è¯„ä¼°æ¡†æ¶ï¼ˆSOLIDè®¾è®¡ï¼‰
â””â”€â”€ live_eval_agent.py        # å®æ—¶è¯„ä¼°Agentå·¥å…·

tests/
â”œâ”€â”€ test_mongodb_deepeval.py  # MongoDBé›†æˆæµ‹è¯•
â”œâ”€â”€ test_agent_evaluation.py  # åŸæœ‰æµ‹è¯•ï¼ˆå·²æ›´æ–°ï¼‰
â””â”€â”€ deepeval_config.py       # é…ç½®æ–‡ä»¶

run_evaluation.py            # å¿«é€Ÿè¿è¡Œè„šæœ¬
EVALUATION_GUIDE.md         # æœ¬æ–‡æ¡£
```

## é…ç½®è¯´æ˜

### ä¿®æ”¹è¯„ä¼°é˜ˆå€¼

ç¼–è¾‘ `tests/deepeval_config.py`:

```python
METRIC_THRESHOLDS = {
    "answer_relevancy": 0.7,    # ä¿®æ”¹ç›¸å…³æ€§é˜ˆå€¼
    "faithfulness": 0.75,        # ä¿®æ”¹å¿ å®åº¦é˜ˆå€¼
    # ...
}
```

### æ·»åŠ æœŸæœ›å·¥å…·æ˜ å°„

```python
EXPECTED_TOOLS_MAP = {
    "æ–°çš„å…³é”®è¯": ["expected_tool_name"],
    # ...
}
```

### å‚æ•°éªŒè¯è§„åˆ™

```python
PARAMETER_VALIDATION_RULES = {
    "tool_name": {
        "param_name": {
            "type": "number",
            "min": 0,
            "max": 1,
            "format": "decimal"  # ç‰¹æ®Šæ ¼å¼è¦æ±‚
        }
    }
}
```

## CI/CDé›†æˆ

### GitHub Actionsç¤ºä¾‹

```yaml
name: Agent Evaluation

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 0 * * *'  # æ¯å¤©è¿è¡Œ

jobs:
  evaluate:
    runs-on: ubuntu-latest

    services:
      mongodb:
        image: mongo:5
        ports:
          - 27017:27017

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install uv
          uv venv
          uv pip install -r requirements.txt

      - name: Run evaluations
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          uv run pytest tests/test_mongodb_deepeval.py -v

      - name: Generate report
        if: always()
        run: |
          uv run python run_evaluation.py --mode report --output report.json

      - name: Upload report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-report
          path: report.json
```

## å®æ—¶è¯„ä¼°é›†æˆ

å°†è¯„ä¼°å·¥å…·æ·»åŠ åˆ°ä¸»Agentä¸­ï¼š

```python
from evaluation.live_eval_agent import create_eval_tools

# åœ¨Agentåˆå§‹åŒ–æ—¶æ·»åŠ è¯„ä¼°å·¥å…·
agent = Agent(
    ...,
    tools=[
        ...existing_tools,
        *create_eval_tools()  # æ·»åŠ è¯„ä¼°å·¥å…·
    ]
)
```

ç„¶åå¯ä»¥åœ¨å¯¹è¯ä¸­ä½¿ç”¨ï¼š
- "è¯„ä¼°æœ€è¿‘çš„å“åº”è´¨é‡"
- "æ£€æŸ¥ä¼šè¯çš„æ€§èƒ½æŒ‡æ ‡"
- "è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"

## æœ€ä½³å®è·µ

### 1. å®šæœŸè¯„ä¼°
- æ¯æ—¥è¿è¡ŒåŸºå‡†æµ‹è¯•
- PRæ—¶è‡ªåŠ¨è¯„ä¼°
- ç›‘æ§å…³é”®æŒ‡æ ‡è¶‹åŠ¿

### 2. æµ‹è¯•ç”¨ä¾‹ç®¡ç†
- ä»ç”Ÿäº§æ•°æ®ä¸­é€‰æ‹©ä»£è¡¨æ€§ç”¨ä¾‹
- å®šæœŸæ›´æ–°æœŸæœ›å·¥å…·æ˜ å°„
- è°ƒæ•´é˜ˆå€¼ä»¥åæ˜ å®é™…éœ€æ±‚

### 3. æ€§èƒ½ä¼˜åŒ–
- ç›‘æ§Tokenä½¿ç”¨è¶‹åŠ¿
- è¯†åˆ«å“åº”æ—¶é—´ç“¶é¢ˆ
- ä¼˜åŒ–å·¥å…·è°ƒç”¨é“¾

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•å¤„ç†è¯„ä¼°å¤±è´¥ï¼Ÿ
A: æ£€æŸ¥å¤±è´¥åŸå› ï¼Œå¯èƒ½éœ€è¦ï¼š
- è°ƒæ•´é˜ˆå€¼ï¼ˆå¦‚æœå¤ªä¸¥æ ¼ï¼‰
- ä¼˜åŒ–Agentæç¤ºè¯
- æ”¹è¿›å·¥å…·é€‰æ‹©é€»è¾‘

### Q: å¦‚ä½•æ·»åŠ æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Ÿ
A: åœ¨ `deepeval_config.py` ä¸­æ·»åŠ é…ç½®ï¼Œç„¶ååœ¨æµ‹è¯•ä¸­å®ç°è¯„ä¼°é€»è¾‘ã€‚

### Q: è¯„ä¼°éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ
A: å–å†³äºæµ‹è¯•ç”¨ä¾‹æ•°é‡å’ŒAPIè°ƒç”¨ï¼š
- å¿«é€Ÿè¯„ä¼°ï¼ˆ5ä¸ªç”¨ä¾‹ï¼‰ï¼šçº¦30ç§’
- å®Œæ•´æµ‹è¯•ï¼ˆ20ä¸ªç”¨ä¾‹ï¼‰ï¼šçº¦2-3åˆ†é’Ÿ
- åŸºå‡†æµ‹è¯•ï¼ˆ100ä¸ªç”¨ä¾‹ï¼‰ï¼šçº¦5-10åˆ†é’Ÿ

## è¯„ä¼°ç»“æœè§£è¯»

### è‰¯å¥½çš„æŒ‡æ ‡èŒƒå›´

âœ… **ä¼˜ç§€**
- Answer Relevancy: > 0.85
- Faithfulness: > 0.85
- Tool Accuracy: > 0.90
- Response Time: < 2s

ğŸŸ¡ **å¯æ¥å—**
- Answer Relevancy: 0.70 - 0.85
- Faithfulness: 0.75 - 0.85
- Tool Accuracy: 0.80 - 0.90
- Response Time: 2-5s

âŒ **éœ€è¦æ”¹è¿›**
- Answer Relevancy: < 0.70
- Faithfulness: < 0.75
- Tool Accuracy: < 0.80
- Response Time: > 5s

## æ•…éšœæ’é™¤

### MongoDBè¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥MongoDBæ˜¯å¦è¿è¡Œ
docker ps | grep mongo

# å¯åŠ¨MongoDB
docker run -d -p 27017:27017 --name mongodb mongo:5
```

### OpenAI APIé”™è¯¯
```bash
# ç¡®ä¿è®¾ç½®äº†APIå¯†é’¥
export OPENAI_API_KEY="your-key-here"

# æˆ–åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®
echo "OPENAI_API_KEY=your-key-here" >> .env
```

### æ²¡æœ‰æµ‹è¯•æ•°æ®
```bash
# å…ˆè¿è¡ŒAgentç”Ÿæˆæ•°æ®
uv run python src/agent/loan_advisor_agent.py

# æˆ–ä½¿ç”¨analyze_agent_behavior.pyç”Ÿæˆ
uv run python analyze_agent_behavior.py
```

## æ€»ç»“

è¿™ä¸ªè¯„ä¼°ç³»ç»Ÿæä¾›äº†ï¼š
1. âœ… **é›¶ä¾µå…¥** - ä¸ä¿®æ”¹ç°æœ‰Agentä»£ç 
2. âœ… **çœŸå®æ•°æ®** - ä»MongoDBè·å–ç”Ÿäº§æ•°æ®
3. âœ… **å¤šç»´è¯„ä¼°** - è´¨é‡ã€æ€§èƒ½ã€å·¥å…·ä½¿ç”¨ç­‰
4. âœ… **çµæ´»é…ç½®** - æ˜“äºè°ƒæ•´å’Œæ‰©å±•
5. âœ… **CI/CDå‹å¥½** - æ”¯æŒè‡ªåŠ¨åŒ–æµ‹è¯•

å¼€å§‹ä½¿ç”¨ï¼š
```bash
uv run python run_evaluation.py --mode recent
```

Happy Evaluating! ğŸš€